{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Convnets\n",
    "Convolutional networks are not only great at viusla processing tasks, but allow som understanding of the inner workings of a trained network. As we will see here, we can probe units of convolutional networks an get some insight on what they are sensititve and get some insight about the hierarchichal processing carried out in deep neural nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_utils import ConvLayer, PoolLayer, FullyConnectedLayer\n",
    "from vis_utils import tilePatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receptive field\n",
    "The receptive field is the area of the input image to which a particular unit (neuron) is sensitive.\n",
    "In convolutional networks processing is localized spatially and behaviour replicates across space. This is expressed as a convolution. In their basic form, convolutional units are described by size and stride. The size is the effective window for which local computations are carried out. Stride is the relative displacement between two consecutive local computations. Receptive field are calculated based on the composition of these basic parameters through the layers of a convolutional network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a look at cifar10 dataset\n",
    "Ww ahve gathered some experience with conve nets sing the MINST data set. In this case we will probe neurons from a network trained on a more naturalistic type of stimuli. Cifar 10 is a relatively simple data set described in https://www.cs.toronto.edu/~kriz/cifar.html. The number of training samples is similar to mnist but unlike mnist, cifar 10 contains 32 x 32 color images from 10 classes of objects.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = cPickle.load(fo)\n",
    "    return dict\n",
    "\n",
    "\n",
    "def read_cifar(cifar_dir, one_hot=False, as_images=True):\n",
    "        n_train = 50000\n",
    "        n_test = 10000\n",
    "        data_train = np.ndarray((n_train, 32*32*3), dtype=np.float32)\n",
    "        data_test = np.ndarray((n_test, 32*32*3), dtype=np.float32)\n",
    "        if one_hot is True:\n",
    "            labels_train = np.zeros((n_train, 10), dtype=np.float32)\n",
    "            labels_test = np.zeros((n_test, 10), dtype=np.float32)\n",
    "        else:\n",
    "            labels_train = np.ndarray(n_train, dtype=np.float32)\n",
    "            labels_test = np.ndarray(n_test, dtype=np.float32)\n",
    "        data_ptr = 0\n",
    "        for iBtch in range(5):\n",
    "            tmp_dict = unpickle(cifar_dir + \"data_batch_%d\"%(iBtch+1))\n",
    "            data_train[data_ptr:data_ptr+tmp_dict['data'].shape[0], ::] = tmp_dict['data']\n",
    "            if one_hot is True:\n",
    "                for iSmp in range(data_ptr,data_ptr+len(tmp_dict['labels'])):\n",
    "                    labels_train[iSmp, tmp_dict['labels'][iSmp - data_ptr]] = 1.0\n",
    "            else:\n",
    "                labels_train[data_ptr:data_ptr+len(tmp_dict['labels'])] = np.asarray(tmp_dict['labels'], dtype=labels_train.dtype)\n",
    "            data_ptr += tmp_dict['data'].shape[0]\n",
    "        \n",
    "        tmp_dict = unpickle(cifar_dir + \"test_batch\")\n",
    "        data_test = tmp_dict['data']\n",
    "        if one_hot is True:\n",
    "            for iSmp in range(n_test):\n",
    "                labels_test[iSmp, tmp_dict['labels'][iSmp]] = 1.0\n",
    "        else:\n",
    "            labels_test = np.asarray(tmp_dict['labels'], dtype=labels_train.dtype)\n",
    "        \n",
    "        data_mean = np.mean(data_train, axis=0, keepdims=True)\n",
    "        if as_images is True:\n",
    "            data_train = np.transpose(np.reshape(data_train, [-1, 3, 32, 32]), [0, 2, 3, 1])\n",
    "            data_test = np.transpose(np.reshape(data_test, [-1, 3, 32, 32]), [0, 2, 3, 1])\n",
    "            data_mean = np.transpose(np.reshape(data_mean, [-1, 3, 32, 32]), [0, 2, 3, 1])\n",
    "        return data_train, labels_train, data_test, labels_test, data_mean\n",
    "\n",
    "data_train, labels_train, data_test, labels_test, data_mean = read_cifar(\"../data/cifar/cifar-10-batches-py/\", one_hot=True, as_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digression warning! A little data handler\n",
    "We will introduce our own data handler to retrieve minbatcehs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \"\"\"\n",
    "    Data class takes care of the minibatch management\n",
    "\n",
    "    There are two optional parameters for Data objects.\n",
    "    -- batch_size: if lefts as None will use the entire data set for \n",
    "       each pass.\n",
    "    -- shuffle: wich defaults to true will shuffle data points to feed \n",
    "       the network at each iteration. When a epoch has been reached, \n",
    "       data is reshuffled.\n",
    "    \"\"\"\n",
    "    batch_iter = None \n",
    "    data_size = None\n",
    "    batch_idx = None\n",
    "    crt_idx = None\n",
    "    n_batches = None\n",
    "    shuffle = None\n",
    "    \n",
    "    def __init__(self, data, batch_size=None, shuffle=True):\n",
    "        self.data = data\n",
    "        self.data_size = data.shape[0]\n",
    "        self.shuffle = shuffle\n",
    "        if batch_size is None:\n",
    "            self.batch_size = self.data_size\n",
    "            self.batch_iter = None\n",
    "            self.batch_idx = None\n",
    "            self.shuffle = False\n",
    "        else:\n",
    "            assert self.data_size >= batch_size, 'batch_size exeeds number of data samples'\n",
    "            self.batch_size = batch_size\n",
    "            self.batch_iter = 0\n",
    "        self.n_batches = np.int64(self.data_size / self.batch_size)\n",
    "        leftovers = self.data_size % self.batch_size\n",
    "                \n",
    "    def getBatch(self):\n",
    "        if self.batch_iter is None:\n",
    "            return self.data\n",
    "  \n",
    "        if self.batch_iter == 0:\n",
    "            ## shuffle data at the begining of every epoch\n",
    "            if self.shuffle is True:\n",
    "                self.batch_idx = np.random.permutation(self.data_size)\n",
    "            else:\n",
    "                self.batch_idx = np.arange(self.data_size, dtype=np.int64)\n",
    "            self.batch_idx = np.reshape(self.batch_idx, (self.n_batches, -1))\n",
    "        self.crt_idx = self.batch_idx[self.batch_iter, :]\n",
    "        batch = self.data[self.crt_idx, ::]\n",
    "        self.batch_iter += 1\n",
    "        if self.batch_iter == self.n_batches:\n",
    "            self.batch_iter = 0\n",
    "        return batch\n",
    "\n",
    "    def getDataAsIn(self, ref_data_object=None):\n",
    "        \"\"\"\n",
    "        This is an auxiliary method with the purpose of selecting\n",
    "        the corresponding data-target pairs. \n",
    "        \"\"\"\n",
    "        if ref_data_object.crt_idx is not None:\n",
    "            return self.data[ref_data_object.crt_idx, ::]\n",
    "        else:\n",
    "            return self.data\n",
    "\n",
    "class CifarData(object):\n",
    "    def __init__(self, data, labels, batch_size=None):\n",
    "        self.data = Data(data, batch_size=batch_size)\n",
    "        self.labels = Data(labels)\n",
    "    \n",
    "    def next_batch(self):\n",
    "        return self.data.getBatch(), self.labels.getDataAsIn(self.data)\n",
    "\n",
    "cifar_train = CifarData(data_train, labels_train, batch_size=100)\n",
    "\n",
    "#cifar_train.next_batch()\n",
    "cifar_test = CifarData(data_test, labels_test, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training cost 2.3026, training accuracy 0.06, test accuracy 0.0969\n",
      "step 1000, training cost 0.988559, training accuracy 0.61, test accuracy 0.5922\n",
      "step 2000, training cost 0.759493, training accuracy 0.71, test accuracy 0.674\n",
      "step 3000, training cost 0.683286, training accuracy 0.73, test accuracy 0.7145\n",
      "step 4000, training cost 0.515314, training accuracy 0.83, test accuracy 0.7283\n",
      "step 5000, training cost 0.71638, training accuracy 0.72, test accuracy 0.7357\n",
      "step 6000, training cost 0.368268, training accuracy 0.87, test accuracy 0.7481\n",
      "step 7000, training cost 0.403672, training accuracy 0.85, test accuracy 0.7538\n",
      "step 8000, training cost 0.484691, training accuracy 0.83, test accuracy 0.7581\n",
      "step 9000, training cost 0.421426, training accuracy 0.86, test accuracy 0.7517\n"
     ]
    }
   ],
   "source": [
    "class Cifar10ConvNet():\n",
    "    def __init__(self):\n",
    "        self.conv1 = ConvLayer((5, 5, 3, 32), 1,'relu', stddev=0.0001, bias=0.0)\n",
    "        self.pool1 = PoolLayer((3, 3), 2,'MAX', 'VALID')\n",
    "        self.conv2 = ConvLayer((5, 5, 32, 32), 1,'relu', stddev=0.01, bias=0.0)\n",
    "        self.pool2 = PoolLayer((3, 3), 2,'MAX', 'VALID')\n",
    "        self.conv3 = ConvLayer((5, 5, 32, 64), 1,'relu', stddev=0.01, bias=0.0)\n",
    "        self.pool3 = PoolLayer((3, 3), 2, 'AVG', 'VALID')\n",
    "        self.fc4 = FullyConnectedLayer((9*64, 10), 'identity', stddev=0.01, bias=0.0)\n",
    "\n",
    "        \n",
    "    def forward(self, X):\n",
    "        conv1 = self.conv1.forward(X)\n",
    "        pool1 = self.pool1.forward(conv1)\n",
    "        conv2 = self.conv2.forward(pool1)\n",
    "        pool2 = self.pool2.forward(conv2)\n",
    "        conv3 = self.conv3.forward(pool2)\n",
    "        pool3 = self.pool3.forward(conv3)\n",
    "        fc4 = self.fc4.forward(tf.reshape(pool3, [-1,9*64]))\n",
    "        return fc4\n",
    "\n",
    "my_net = Cifar10ConvNet()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "pred = my_net.forward(x)\n",
    "# create loss to train\n",
    "label = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "# Use combined logsig and xent to have numerically stable gradients\n",
    "xent_cost = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=pred))\n",
    "train_step = tf.train.MomentumOptimizer(0.001, 0.9).minimize(xent_cost)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# Train\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "n_test_iter = 100\n",
    "for i in range(10000):\n",
    "    batch_xs, batch_ys = cifar_train.next_batch()\n",
    "    batch_xs = batch_xs - data_mean\n",
    "    ## display training accuracy \n",
    "    if i%1000 == 0:\n",
    "        test_accuracy = 0.0;\n",
    "        for iTst in range(n_test_iter):\n",
    "            batch_test_xs, batch_test_ys = cifar_test.next_batch()\n",
    "            batch_test_xs = batch_test_xs - data_mean\n",
    "            test_accuracy += accuracy.eval(feed_dict={\n",
    "                x:batch_test_xs, label: batch_test_ys})\n",
    "        test_accuracy /=n_test_iter\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "                x:batch_xs, label: batch_ys})\n",
    "        train_cost = xent_cost.eval(feed_dict={\n",
    "                x:batch_xs, label: batch_ys})\n",
    "        print(\"step %d, training cost %g, training accuracy %g, test accuracy %g\"%(i, train_cost, train_accuracy, test_accuracy))\n",
    "    ## \n",
    "    sess.run(train_step, feed_dict={x: batch_xs, label: batch_ys})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.311972826719 -0.326676696539\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADBCAYAAAAEqOEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f220c4dfe10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv1_W = my_net.conv1.params['W'].eval()\n",
    "conv1_W.shape\n",
    "conv1_filters = tilePatches(np.reshape(conv1_W, [5, 5, 3, -1]), ncol=8)\n",
    "print(np.max(conv1_filters), np.min(conv1_filters))\n",
    "plt.imshow(2*conv1_filters+0.5, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the size of a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32 32]\n",
      "[15 15]\n",
      "[15 15]\n",
      "[7 7]\n",
      "[7 7]\n",
      "[3 3]\n"
     ]
    }
   ],
   "source": [
    "def mapSize(input_sz, filter_size, stride=1, padding=0):\n",
    "    return np.int32((input_sz + padding - filter_size)/stride + 1)\n",
    "\n",
    "input_map = np.asarray([32, 32])\n",
    "conv1_fz = np.asarray(my_net.conv1.shape[0:2])\n",
    "conv1_map = mapSize(input_map, conv1_fz, padding=(conv1_fz-1))\n",
    "print(conv1_map)\n",
    "\n",
    "pool1_fz = np.asarray(my_net.pool1.shape[1:3])\n",
    "pool1_map = mapSize(conv1_map, pool1_fz, stride=my_net.pool1.stride[1:3])\n",
    "print(pool1_map)\n",
    "\n",
    "\n",
    "conv2_fz = np.asarray(my_net.conv2.shape[0:2])\n",
    "conv2_map = mapSize(pool1_map, conv2_fz, padding=(conv2_fz-1))\n",
    "print(conv2_map)\n",
    "\n",
    "pool2_fz = np.asarray(my_net.pool2.shape[1:3])\n",
    "pool2_map = mapSize(conv2_map, pool2_fz, stride=my_net.pool2.stride[1:3])\n",
    "print(pool2_map)\n",
    "\n",
    "\n",
    "conv3_fz = np.asarray(my_net.conv3.shape[0:2])\n",
    "conv3_map = mapSize(pool2_map, conv3_fz, padding=(conv3_fz-1))\n",
    "print(conv3_map)\n",
    "\n",
    "pool3_fz = np.asarray(my_net.pool3.shape[1:3])\n",
    "pool3_map = mapSize(conv3_map, pool3_fz, stride=my_net.pool3.stride[1:3])\n",
    "print(pool3_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing receptive field size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 rf size\n",
      "[5 5]\n",
      "pool1 rf size\n",
      "[7 7]\n",
      "conv2 rf size\n",
      "[15 15]\n",
      "pool2 rf size\n",
      "[17 17]\n",
      "conv3 rf size\n",
      "[25 25]\n",
      "pool3 rf size\n",
      "[27 27]\n",
      "fc4 rf size\n",
      "[31 31]\n"
     ]
    }
   ],
   "source": [
    "def rfSize(out_filter_size, in_filter_size, in_stride=1):\n",
    "    return (out_filter_size-1)*in_stride + in_filter_size\n",
    "\n",
    "conv1_rf = rfSize(conv1_fz, np.asarray([1,1]))\n",
    "print(\"conv1 rf size\")\n",
    "print(conv1_rf)\n",
    "\n",
    "pool1_rf = rfSize(pool1_fz, conv1_fz)\n",
    "print(\"pool1 rf size\")\n",
    "print(pool1_rf)\n",
    "\n",
    "pool1_stride = my_net.pool1.stride[1:3]\n",
    "conv2_rf = rfSize(conv2_fz, pool1_rf, in_stride=pool1_stride)\n",
    "print(\"conv2 rf size\")\n",
    "print(conv2_rf)\n",
    "\n",
    "pool2_rf = rfSize(pool2_fz, conv2_rf)\n",
    "print(\"pool2 rf size\")\n",
    "print(pool2_rf)\n",
    "\n",
    "pool2_stride = my_net.pool2.stride[1:3]\n",
    "conv3_rf = rfSize(conv3_fz, pool2_rf, in_stride=pool2_stride)\n",
    "print(\"conv3 rf size\")\n",
    "print(conv3_rf)\n",
    "\n",
    "pool3_rf = rfSize(pool3_fz, conv3_rf)\n",
    "print(\"pool3 rf size\")\n",
    "print(pool3_rf)\n",
    "\n",
    "pool3_stride = my_net.pool3.stride[1:3]\n",
    "fc4_fz = np.asarray([3, 3])\n",
    "fc4_rf = rfSize(fc4_fz, pool3_rf, in_stride=pool3_stride)\n",
    "print(\"fc4 rf size\")\n",
    "print(fc4_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize second layer units\n",
    "stimuli_x = tf.placeholder\n",
    "unit_idx = 0\n",
    "\n",
    "class CifarV2Net():\n",
    "    def __init__(self):\n",
    "        self.conv1 = ConvLayer((5, 5, 3, 32), 1,'relu', stddev=0.0001, bias=0.0)\n",
    "        self.pool1 = PoolLayer((3, 3), 2,'MAX', 'VALID')\n",
    "        self.conv2 = ConvLayer((5, 5, 32, 32), 1,'relu', stddev=0.01, bias=0.0)\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        conv1 = self.conv1.forward(X)\n",
    "        pool1 = self.pool1.forward(conv1)\n",
    "        conv2 = self.conv2.forward(pool1)\n",
    "        return conv2\n",
    "\n",
    "my_v2net = CifarV2Net()\n",
    "## use learned parameters to visualize units\n",
    "my_v2net.conv1.params['W'] = my_net.conv1.params['W']\n",
    "my_v2net.conv1.params['b'] = my_net.conv1.params['b']\n",
    "my_v2net.conv2.params['W'] = my_net.conv2.params['W']\n",
    "my_v2net.conv2.params['b'] = my_net.conv2.params['b']\n",
    "\n",
    "vis_cost = tf.reduce_mean(tf.square(my_v2net.forward(stimuli_x)[:,0,0,unit_idx]))\n",
    "train_stimuli_update = tf.train.GradientDescentOptimizer(0.1).compute_gradients(vis_cost, var_list=[stimuli])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stimuli = np.random.normal(size=[1, conv2_rf[0], conv2_rf[1], 3])\n",
    "for i in range(10000):\n",
    "    ## display training accuracy \n",
    "    sess.run(train_stimuli_update, feed_dict={x: stimuli})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
