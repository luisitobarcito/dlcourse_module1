{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional layer\n",
    "In convolutional networks processing is localized spatially and behaviour replicates across space. This is expressed as a convolution. In their basic form, convolutional units are described by size and stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a few activation functions to play with\n",
    "def halfSquare(x):\n",
    "    return tf.square(tf.nn.relu(x))\n",
    "\n",
    "def myIdty(x):\n",
    "    return x\n",
    "\n",
    "act_list = {'sigmoid': tf.nn.sigmoid,     \\\n",
    "            'tanh': tf.nn.tanh,        \\\n",
    "            'relu': tf.nn.relu,        \\\n",
    "            'abs': tf.abs,         \\\n",
    "            'square': tf.square,      \\\n",
    "            'half_square': halfSquare, \\\n",
    "            'identity': myIdty}\n",
    "\n",
    "def initWeightBias(shape, stddev=0.1, bias=0.1): \n",
    "    initW = tf.truncated_normal(shape, stddev=stddev)\n",
    "    initBias = tf.constant(bias, shape=[shape[-1]])\n",
    "    return initW, initBias\n",
    "\n",
    "class ConvLayer(object):\n",
    "    def __init__(self, shape, stride, activation, padding='SAME'):\n",
    "        self.shape = shape\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        initW, initBias = initWeightBias(self.shape)\n",
    "        self.params = {}\n",
    "        self.params['W'] = tf.Variable(initW)\n",
    "        self.params['b'] = tf.Variable(initBias)\n",
    "        self.g = act_list[activation]\n",
    "    \n",
    "    def forward(self, X):\n",
    "        Z = tf.nn.conv2d(X, self.params['W'], strides=[1, self.stride, self.stride, 1], padding=self.padding) + self.params['b']\n",
    "        return self.g(Z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool_type = {'MAX':tf.nn.max_pool, \\\n",
    "             'AVG':tf.nn.avg_pool}\n",
    "class PoolLayer(object):\n",
    "    def __init__(self, shape, stride, pooling='AVG', padding='SAME'):\n",
    "        self.shape = (1, shape[0], shape[1], 1)\n",
    "        self.stride = (1, stride, stride, 1)\n",
    "        self.pooltype = pooling\n",
    "        self.padding = padding\n",
    "        self.pool = pool_type[self.pooltype]\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.pool(X, self.shape, self.stride, self.padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FullyConnectedLayer(object):\n",
    "    def __init__(self, shape, activation):\n",
    "        self.shape = shape\n",
    "        initW, initBias = initWeightBias(self.shape)\n",
    "        self.params = {}\n",
    "        self.params['W'] = tf.Variable(initW)\n",
    "        self.params['b'] = tf.Variable(initBias)\n",
    "        self.g = act_list[activation]\n",
    "    \n",
    "    def forward(self, X):\n",
    "        Z = tf.matmul(X, self.params['W']) + self.params['b']\n",
    "        return self.g(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MnistConvNet():\n",
    "    def __init__(self):\n",
    "        self.conv1 = ConvLayer((5, 5, 1, 6), 1,'relu')\n",
    "        self.pool1 = PoolLayer((2, 2), 2,'MAX', 'VALID')\n",
    "        self.conv2 = ConvLayer((5, 5, 6, 16), 1,'relu', 'VALID')\n",
    "        self.pool2 = PoolLayer((2, 2), 2,'MAX', 'VALID')\n",
    "        self.conv3 = ConvLayer((5, 5, 16, 120), 1,'relu', 'VALID')\n",
    "        self.fc4 = FullyConnectedLayer((120, 84), 'relu')\n",
    "        self.fc5 = FullyConnectedLayer((84, 10), 'identity')\n",
    "        \n",
    "    def forward(self, X):\n",
    "        conv1 = self.conv1.forward(X)\n",
    "        pool1 = self.pool1.forward(conv1)\n",
    "        conv2 = self.conv2.forward(pool1)\n",
    "        pool2 = self.pool2.forward(conv2)\n",
    "        conv3 = self.conv3.forward(pool2)\n",
    "        fc4 = self.fc4.forward(tf.reshape(conv3, [-1, 120]))\n",
    "        fc5 = self.fc5.forward(fc4)\n",
    "        return fc5\n",
    "my_net = MnistConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "step 0, training cost 2.31126, training accuracy 0.07\n",
      "step 1000, training cost 0.211454, training accuracy 0.95\n",
      "step 2000, training cost 0.326092, training accuracy 0.89\n",
      "step 3000, training cost 0.103977, training accuracy 0.97\n",
      "step 4000, training cost 0.190011, training accuracy 0.95\n",
      "step 5000, training cost 0.0799839, training accuracy 0.98\n",
      "step 6000, training cost 0.151034, training accuracy 0.96\n",
      "step 7000, training cost 0.049047, training accuracy 0.98\n",
      "step 8000, training cost 0.0468301, training accuracy 0.98\n",
      "step 9000, training cost 0.113455, training accuracy 0.96\n"
     ]
    }
   ],
   "source": [
    "# Data handler included in TF examples (downloads data)\n",
    "mnist = input_data.read_data_sets('../data/mnist', one_hot=True)\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "pred = my_net.forward(x)\n",
    "# create loss to train\n",
    "label = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "# Use combined logsig and xent to have numerically stable gradients\n",
    "xent_cost = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=pred))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(xent_cost)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# Train\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "for i in range(10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    ## display training accuracy \n",
    "    if i%1000 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "                x:np.reshape(batch_xs, [-1, 28, 28, 1]), label: batch_ys})\n",
    "        train_cost = xent_cost.eval(feed_dict={\n",
    "                x:np.reshape(batch_xs, [-1, 28, 28,1]), label: batch_ys})\n",
    "        print(\"step %d, training cost %g, training accuracy %g\"%(i, train_cost, train_accuracy))\n",
    "    ## \n",
    "    sess.run(train_step, feed_dict={x: np.reshape(batch_xs, [-1, 28, 28,1]), label: batch_ys})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
